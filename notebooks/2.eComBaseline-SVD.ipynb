{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Simple Collaborative Filtering model using Matrix Factorization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import Dataset, Reader, SVD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yingkang/4thBrain/GNN-eCommerce\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "with open(\"config.yaml\") as config_file:\n",
    "    config = yaml.safe_load(config_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Interaction Matrix from csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "interaction_matrix = pd.read_csv(config['data']['preprocessed'] + \"u_i_weight_0.01_0.1_-0.09.csv\")\n",
    "# file 2 -- u_i_weight_0.15_0.35_-0.2.csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "mini = interaction_matrix.head(1000)\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "surprise_dataset = Dataset.load_from_df(mini[['user_id', 'item_id', 'weight']], reader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds)\n",
    "algo = SVD()\n",
    "\n",
    "for trainset, testset in kf.split(surprise_dataset):\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "     userId   itemId  actual  prediction\n0  20554973  5676936    0.01    0.041316\n1  20554973  5813483    0.01    0.041316\n2  20554973  5650596    0.02    0.041316\n3  19762782  5801431    0.01    0.205881\n4  20554973  5847338    0.01    0.041316",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>itemId</th>\n      <th>actual</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20554973</td>\n      <td>5676936</td>\n      <td>0.01</td>\n      <td>0.041316</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20554973</td>\n      <td>5813483</td>\n      <td>0.01</td>\n      <td>0.041316</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20554973</td>\n      <td>5650596</td>\n      <td>0.02</td>\n      <td>0.041316</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>19762782</td>\n      <td>5801431</td>\n      <td>0.01</td>\n      <td>0.205881</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20554973</td>\n      <td>5847338</td>\n      <td>0.01</td>\n      <td>0.041316</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(predictions)\n",
    "predictions.drop(\"details\", inplace=True, axis=1)\n",
    "predictions.columns = ['userId', 'itemId', 'actual', 'prediction']\n",
    "predictions.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(36, 198)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predictions.pivot_table(index='userId', columns='itemId', values='prediction').fillna(0)\n",
    "predictions.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.15431949972487433 | recall: 0.12702260807694613 | users count: 76127\n",
      "precision: 0.15476842531803514 | recall: 0.12748756584243737 | users count: 76072\n",
      "precision: 0.15401223197329858 | recall: 0.12714085528976968 | users count: 76003\n",
      "precision: 0.15329944747097216 | recall: 0.12593473286268783 | users count: 76152\n",
      "precision: 0.15532556263789318 | recall: 0.12743901449786119 | users count: 75865\n",
      "average precision: 0.15434503342501468 | average recall: 0.12700495531394046\n"
     ]
    }
   ],
   "source": [
    "# n fold cross validation\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds)\n",
    "algo = SVD()\n",
    "\n",
    "ps = []  # precisions\n",
    "rs = []  # recalls\n",
    "for trainset, testset in kf.split(surprise_dataset):\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10, est_threshold=0.5, true_threshold=1.0)\n",
    "\n",
    "    # Precision and recall can then be averaged over all users\n",
    "    average_p = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    average_r = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    print(\"precision:\", average_p, \"| recall:\", average_r, \"| users count:\", len(recalls))\n",
    "    ps.append(average_p)\n",
    "    rs.append(average_r)\n",
    "\n",
    "print(\"average precision:\", sum(ps) / len(ps), \"| average recall:\", sum(rs) / len(rs) )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Precion@K and Recall@K metric function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=10, est_threshold=0.5, true_threshold=1.0):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\n",
    "    Ref: https://surprise.readthedocs.io/en/stable/FAQ.html\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= true_threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # skip the user if the user does not have relevant items (i.e. has not bought at least one item)\n",
    "        if n_rel == 0:\n",
    "            continue\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= est_threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(\n",
    "            ((true_r >= true_threshold) and (est >= est_threshold))\n",
    "            for (est, true_r) in user_ratings[:k]\n",
    "        )\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel\n",
    "\n",
    "    return precisions, recalls\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Further Work\n",
    "Use event time to influence the weight of the event. i.e. More recent events carry more weight."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
