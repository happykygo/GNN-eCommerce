{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LightGCN model RecSys"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn\n",
    "from lightgcn import LightGCN\n",
    "# from torch_geometric.nn import LightGCN\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from utils import *\n",
    "pd.set_option('display.max_colwidth', None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yingkang/4thBrain/GNN-eCommerce\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'base': {'random_seed': 42},\n 'data': {'cosmetic_shop': 'data/raw/cosmetic-shop-ecommerce-events/',\n  'preprocessed': 'data/preprocessed/'},\n 'training': {'event_type_weights': {'view': 0.01,\n   'cart': 0.1,\n   'remove_from_cart': -0.09,\n   'purchase': 1.0}},\n 'reports': None}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd ..\n",
    "with open(\"params.yaml\") as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Interaction Matrix from csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "interaction_matrix = pd.read_csv(config['data']['preprocessed'] + \"interaction_matrix.csv\")\n",
    "interaction_matrix = interaction_matrix.rename(columns={\"product_id\": \"item_id\"})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "im = interaction_matrix[['user_id', 'item_id', 'weight']].copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data size:  10157408 , unique user:  1639358 , unique items:  54571\n"
     ]
    }
   ],
   "source": [
    "print('Total data size: ', len(im), ', unique user: ', im.user_id.nunique(), ', unique items: ', im.item_id.nunique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# ying = im.head(1000)\n",
    "# ying"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# train_df, test_df = train_test_split(ying, test_size=0.3, random_state=16)\n",
    "# test_df, val_df = train_test_split(test_df, test_size=0.5, random_state=16)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# ?? Should user never purchase removed at the beginning ??? NO for now!!\n",
    "# mini_im = purchase_users(im)\n",
    "mini_im = im.sample(100000, random_state=1)  #100000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini dataset size:  100000 , Users at least purchased once:  18729\n"
     ]
    }
   ],
   "source": [
    "print('Mini dataset size: ', len(mini_im), ', Users at least purchased once: ', len(purchase_users(mini_im)))\n",
    "# print('Valid data percentage: ', f'{len(mini_im)/len(im):.2%}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# mini_im.loc[~mini_im['user_id'].isin(u_id_filter)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare Train/ Val/ Test dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(mini_im, test_size=0.3, random_state=16)\n",
    "test_df, val_df = train_test_split(test_df, test_size=0.5, random_state=16)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini set unique user:  74976 , unique items:  25645\n",
      "Train Size  :  70000\n",
      "Val Size :  15000\n",
      "Test Size :  15000\n"
     ]
    }
   ],
   "source": [
    "print('Mini set unique user: ', mini_im.user_id.nunique(), ', unique items: ', mini_im.item_id.nunique())\n",
    "print(\"Train Size  : \", len(train_df))\n",
    "print(\"Val Size : \", len (val_df))\n",
    "print(\"Test Size : \", len (test_df))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "n_users, n_items, train_df, val_pos_list_df, test_pos_list_df, val_u_i_matrix, test_u_i_matrix = \\\n",
    "    prepare_val_test(train_df, val_df, test_df, device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users :  55837\n",
      "Items :  21848\n",
      "Train Size  :  70000\n",
      "Val Size :  589\n",
      "Test Size :  594\n"
     ]
    }
   ],
   "source": [
    "print(\"Users : \", n_users)\n",
    "print(\"Items : \", n_items)\n",
    "print(\"Train Size  : \", len(train_df))\n",
    "print(\"Val Size : \", len (val_pos_list_df))\n",
    "print(\"Test Size : \", len (test_pos_list_df))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# train_df = train_df.loc[train_df['weight'] == 1].drop_duplicates('user_id_idx')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# users = torch.LongTensor(list(np.repeat(train_df['user_id_idx'], 100)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# p = train_df['item_id_idx_list'].apply(lambda x: sample_pos(x, 100)).tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# torch.LongTensor(p)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "users, pos_items, neg_items = pos_neg_edge_index(train_df, 100, n_users, n_items)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of sample pool:  745000\n"
     ]
    }
   ],
   "source": [
    "print('Size of sample pool: ', len(users))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instantiate model and train/val the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Learnable Embedding :  [torch.Size([77685, 64])]\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 64\n",
    "n_layers = 3\n",
    "LR = 0.005\n",
    "\n",
    "model = LightGCN(num_nodes=n_users+n_items, embedding_dim=latent_dim, num_layers=n_layers)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "print(\"Size of Learnable Embedding : \", [x.shape for x in list(model.parameters())])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def train_and_evl(n_users, n_items, n_neg, train_df, test_u_i_matrix, test_pos_list_df, model, optimizer, device, EPOCHS = 50, BATCH_SIZE = 1024, K = 20, DECAY = 0.0001):\n",
    "    edge_index, edge_weight = df_to_graph(train_df, True)\n",
    "\n",
    "    test_u_i_matrix = test_u_i_matrix.to(device)\n",
    "    edge_index = edge_index.to(device)\n",
    "    edge_weight = edge_weight.to(device)\n",
    "    model.to(device)\n",
    "\n",
    "    bpr_loss_epoch_list = []\n",
    "    reg_loss_epoch_list = []\n",
    "    final_loss_epoch_list = []\n",
    "    recall_epoch_list = []\n",
    "    precision_epoch_list = []\n",
    "\n",
    "    print('bpr_loss | reg_loss | final_loss | precision | recall')\n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        bpr_loss, reg_loss, final_loss = train_loop(train_df, n_users, n_items, n_neg, edge_index, edge_weight, model, optimizer, BATCH_SIZE)\n",
    "\n",
    "        precision, recall = evaluation(model, n_users, n_items, edge_index, edge_weight, test_u_i_matrix, test_pos_list_df, K)\n",
    "\n",
    "        print(bpr_loss, reg_loss, final_loss, precision, recall)\n",
    "        bpr_loss_epoch_list.append(bpr_loss)\n",
    "        reg_loss_epoch_list.append(reg_loss)\n",
    "        final_loss_epoch_list.append(final_loss)\n",
    "        recall_epoch_list.append(recall)\n",
    "        precision_epoch_list.append(precision)\n",
    "\n",
    "    return (\n",
    "        bpr_loss_epoch_list,\n",
    "        reg_loss_epoch_list,\n",
    "        final_loss_epoch_list,\n",
    "        recall_epoch_list,\n",
    "        precision_epoch_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpr_loss | reg_loss | final_loss | precision | recall\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7551efbcd0fd4013b23b908b5f2db717"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m bpr_loss, reg_loss, final_loss, recall, precision \u001B[38;5;241m=\u001B[39m \\\n\u001B[0;32m----> 2\u001B[0m     \u001B[43mtrain_and_evl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_users\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_items\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_u_i_matrix\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_pos_list_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mEPOCHS\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1024\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mK\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDECAY\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0001\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[18], line 17\u001B[0m, in \u001B[0;36mtrain_and_evl\u001B[0;34m(n_users, n_items, n_neg, train_df, test_u_i_matrix, test_pos_list_df, model, optimizer, device, EPOCHS, BATCH_SIZE, K, DECAY)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbpr_loss | reg_loss | final_loss | precision | recall\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(EPOCHS)):\n\u001B[0;32m---> 17\u001B[0m     bpr_loss, reg_loss, final_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_users\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_items\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_neg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m     precision, recall \u001B[38;5;241m=\u001B[39m evaluation(model, n_users, n_items, edge_index, edge_weight, test_u_i_matrix, test_pos_list_df, K)\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28mprint\u001B[39m(bpr_loss, reg_loss, final_loss, precision, recall)\n",
      "File \u001B[0;32m~/4thBrain/GNN-eCommerce/notebooks/utils.py:274\u001B[0m, in \u001B[0;36mtrain_loop\u001B[0;34m(train_df, n_users, n_items, n_neg, edge_index, edge_weight, model, optimizer, BATCH_SIZE)\u001B[0m\n\u001B[1;32m    271\u001B[0m batch_neg_items \u001B[38;5;241m=\u001B[39m neg_items[batch]\n\u001B[1;32m    273\u001B[0m batch_pos_neg_labels \u001B[38;5;241m=\u001B[39m batch_pos_neg_edges(batch_usr, batch_pos_items, batch_neg_items)\n\u001B[0;32m--> 274\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_pos_neg_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    275\u001B[0m size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(batch)\n\u001B[1;32m    277\u001B[0m bpr_loss \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mrecommendation_loss(out[:size], out[size:], \u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m*\u001B[39m size\n",
      "File \u001B[0;32m~/4thBrain/GNN-eCommerce/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/4thBrain/GNN-eCommerce/notebooks/lightgcn.py:121\u001B[0m, in \u001B[0;36mLightGCN.forward\u001B[0;34m(self, edge_index, edge_label_index, edge_weight)\u001B[0m\n\u001B[1;32m    118\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    119\u001B[0m         edge_label_index \u001B[38;5;241m=\u001B[39m edge_index\n\u001B[0;32m--> 121\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_embedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    123\u001B[0m out_src \u001B[38;5;241m=\u001B[39m out[edge_label_index[\u001B[38;5;241m0\u001B[39m]]\n\u001B[1;32m    124\u001B[0m out_dst \u001B[38;5;241m=\u001B[39m out[edge_label_index[\u001B[38;5;241m1\u001B[39m]]\n",
      "File \u001B[0;32m~/4thBrain/GNN-eCommerce/notebooks/lightgcn.py:96\u001B[0m, in \u001B[0;36mLightGCN.get_embedding\u001B[0;34m(self, edge_index, edge_weight)\u001B[0m\n\u001B[1;32m     93\u001B[0m out \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malpha[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers):\n\u001B[0;32m---> 96\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvs\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     97\u001B[0m     out \u001B[38;5;241m=\u001B[39m out \u001B[38;5;241m+\u001B[39m x \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malpha[i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m~/4thBrain/GNN-eCommerce/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/4thBrain/GNN-eCommerce/venv/lib/python3.9/site-packages/torch_geometric/nn/conv/lg_conv.py:53\u001B[0m, in \u001B[0;36mLGConv.forward\u001B[0;34m(self, x, edge_index, edge_weight)\u001B[0m\n\u001B[1;32m     48\u001B[0m     edge_index \u001B[38;5;241m=\u001B[39m gcn_norm(edge_index, \u001B[38;5;28;01mNone\u001B[39;00m, x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode_dim),\n\u001B[1;32m     49\u001B[0m                           add_self_loops\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, flow\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mflow,\n\u001B[1;32m     50\u001B[0m                           dtype\u001B[38;5;241m=\u001B[39mx\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[1;32m     52\u001B[0m \u001B[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001B[39;00m\n\u001B[0;32m---> 53\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                      \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/4thBrain/GNN-eCommerce/venv/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:432\u001B[0m, in \u001B[0;36mMessagePassing.propagate\u001B[0;34m(self, edge_index, size, **kwargs)\u001B[0m\n\u001B[1;32m    429\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m arg \u001B[38;5;129;01min\u001B[39;00m decomp_args:\n\u001B[1;32m    430\u001B[0m         kwargs[arg] \u001B[38;5;241m=\u001B[39m decomp_kwargs[arg][i]\n\u001B[0;32m--> 432\u001B[0m coll_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__collect__\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__user_args__\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    433\u001B[0m \u001B[43m                             \u001B[49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    435\u001B[0m msg_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minspector\u001B[38;5;241m.\u001B[39mdistribute(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmessage\u001B[39m\u001B[38;5;124m'\u001B[39m, coll_dict)\n\u001B[1;32m    436\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_message_forward_pre_hooks\u001B[38;5;241m.\u001B[39mvalues():\n",
      "File \u001B[0;32m~/4thBrain/GNN-eCommerce/venv/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:304\u001B[0m, in \u001B[0;36mMessagePassing.__collect__\u001B[0;34m(self, args, edge_index, size, kwargs)\u001B[0m\n\u001B[1;32m    302\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, Tensor):\n\u001B[1;32m    303\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__set_size__(size, dim, data)\n\u001B[0;32m--> 304\u001B[0m             data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__lift__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    306\u001B[0m         out[arg] \u001B[38;5;241m=\u001B[39m data\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_torch_sparse_tensor(edge_index):\n",
      "File \u001B[0;32m~/4thBrain/GNN-eCommerce/venv/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:239\u001B[0m, in \u001B[0;36mMessagePassing.__lift__\u001B[0;34m(self, src, edge_index, dim)\u001B[0m\n\u001B[1;32m    237\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    238\u001B[0m     index \u001B[38;5;241m=\u001B[39m edge_index[dim]\n\u001B[0;32m--> 239\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msrc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex_select\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mIndexError\u001B[39;00m, \u001B[38;5;167;01mRuntimeError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    241\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m index\u001B[38;5;241m.\u001B[39mmin() \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m index\u001B[38;5;241m.\u001B[39mmax() \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m src\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode_dim):\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "bpr_loss, reg_loss, final_loss, recall, precision = \\\n",
    "    train_and_evl(n_users, n_items, 100, train_df, val_u_i_matrix, val_pos_list_df, model, optimizer, device=device, EPOCHS = 50, BATCH_SIZE = 1024, K = 20, DECAY = 0.0001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "8264"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# users, pos_items, neg_items = pos_neg_edge_index(train_df, n_users, n_items)\n",
    "# len(pos_items)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "817 pos sample out of 7000 train data: Pos_Sample_Rate = 11.67%\n",
    "848091 pos sample out of 7110185 train data: Pos_Sample Rate = 11.93%"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# idx = list(range(len(users)))\n",
    "# random.shuffle(idx)\n",
    "# loader = DataLoader(idx, batch_size=100, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# model.train()\n",
    "# for batch in loader:\n",
    "#     optimizer.zero_grad()\n",
    "#\n",
    "#     batch_usr = users[batch]\n",
    "#     batch_pos_items = pos_items[batch]\n",
    "#     batch_neg_items = neg_items[batch]\n",
    "#\n",
    "#     batch_pos_neg_labels = batch_pos_neg_edges(batch_usr, batch_pos_items, batch_neg_items)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[32115, 28194, 21421, 18533,  6468, 23668, 42851, 10046, 40984, 49278,\n         21264,  5819, 24200, 33788, 10791, 26484, 50754, 25508, 21396, 15941,\n         22990, 41688, 17044, 26760, 42211,  2168, 12126,  4852,  9065, 38664,\n         22303, 27577, 38019, 26925, 40179,  5836,  7054, 49337, 15728, 20238,\n         18254, 12742, 23836, 42906, 47775, 32403,  9764, 18732,  6613,  5310,\n         27452, 17747, 40770, 11488, 35654, 27395,  6554, 22329, 47689, 29664,\n          5811, 34993, 33453, 42565, 32115, 28194, 21421, 18533,  6468, 23668,\n         42851, 10046, 40984, 49278, 21264,  5819, 24200, 33788, 10791, 26484,\n         50754, 25508, 21396, 15941, 22990, 41688, 17044, 26760, 42211,  2168,\n         12126,  4852,  9065, 38664, 22303, 27577, 38019, 26925, 40179,  5836,\n          7054, 49337, 15728, 20238, 18254, 12742, 23836, 42906, 47775, 32403,\n          9764, 18732,  6613,  5310, 27452, 17747, 40770, 11488, 35654, 27395,\n          6554, 22329, 47689, 29664,  5811, 34993, 33453, 42565],\n        [65483, 73582, 71096, 59480, 57437, 65869, 58913, 69969, 57702, 55987,\n         56372, 57695, 67011, 73307, 63613, 57234, 58261, 61901, 63693, 55920,\n         74727, 70382, 69596, 73294, 69127, 67584, 76289, 65917, 61016, 68699,\n         55950, 65621, 59671, 61457, 58046, 65310, 63531, 56707, 71452, 68078,\n         58560, 66147, 69010, 63618, 66173, 57052, 67495, 63619, 58747, 64039,\n         59406, 71086, 56211, 64229, 73289, 75289, 60777, 67000, 76652, 67510,\n         74739, 64391, 58888, 62499, 73627, 72391, 71602, 60277, 72449, 60636,\n         70112, 63859, 65643, 75968, 58533, 59516, 68760, 62677, 69692, 72058,\n         59923, 57456, 63148, 73611, 69144, 70876, 70534, 68849, 68454, 70600,\n         77227, 72918, 70803, 70178, 67295, 69957, 63263, 76848, 70758, 58220,\n         68256, 60261, 71769, 67492, 75423, 76818, 68111, 73837, 65526, 59921,\n         71095, 69976, 71556, 70025, 63907, 73842, 59839, 71385, 61646, 65143,\n         65215, 66585, 59104, 76169, 68861, 58566, 72142, 66503]])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_pos_neg_labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(55920)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_pos_neg_labels[1].min()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 7.8876e-04,  6.6548e-04,  2.9060e-04,  5.8692e-04,  1.0170e-03,\n         2.4106e-04,  7.3517e-04,  9.2481e-04,  8.5302e-04,  3.4077e-04,\n         8.7647e-04,  5.4225e-04,  7.7014e-04,  2.6808e-04,  2.2831e-04,\n         4.8092e-04,  7.1286e-04,  5.4340e-04,  4.8758e-04,  3.8278e-04,\n         5.8570e-04,  1.1317e-04,  5.9058e-04,  8.1913e-04,  3.6317e-04,\n         9.2634e-04,  2.7700e-04,  2.9253e-04,  4.8097e-04,  3.0643e-04,\n         4.2362e-04,  4.0224e-04,  6.0253e-04,  7.5705e-04,  9.7720e-04,\n         6.4622e-04,  2.8558e-04,  4.4712e-04,  5.3895e-04,  3.5354e-04,\n         4.0005e-04,  5.8406e-04,  4.5432e-04,  4.0665e-04,  5.5185e-04,\n         3.0077e-04,  2.7294e-04,  7.7393e-04,  5.5425e-04,  6.9607e-04,\n         3.6969e-04,  4.5125e-04,  8.1844e-04,  4.5082e-04,  2.1936e-04,\n         8.2935e-04,  8.0989e-04,  8.6049e-04,  4.5159e-04,  5.2694e-04,\n         8.0631e-04,  8.8362e-04,  3.1063e-04,  3.9110e-04, -8.7095e-05,\n        -1.8979e-05,  5.5088e-05, -2.3548e-05, -1.9942e-05,  2.4228e-05,\n         1.0008e-05, -4.5995e-05, -5.9209e-05, -5.7673e-06,  9.5538e-05,\n        -3.3913e-05, -6.2333e-05, -5.6131e-05, -7.1719e-06, -1.7059e-05,\n         2.6450e-05,  6.2314e-05,  1.0485e-04, -5.0102e-05, -1.5917e-05,\n         6.9845e-06,  1.2445e-04,  1.7138e-05,  1.0459e-04,  7.8306e-05,\n         6.4367e-05,  6.3275e-06,  1.0178e-05, -2.1094e-05, -2.7120e-05,\n         1.0543e-05, -6.5895e-07,  2.8101e-05,  3.0637e-05,  8.8070e-06,\n         2.7401e-05,  2.8737e-05,  1.2274e-04,  5.0252e-06,  1.3496e-04,\n         7.6514e-05, -3.7586e-05,  1.8358e-05,  4.5835e-05, -1.2507e-05,\n        -4.2826e-05, -1.3342e-04, -9.4955e-06, -2.1493e-04,  7.7741e-05,\n        -9.3089e-05,  1.0306e-04, -1.0056e-04, -7.5348e-06,  2.9606e-05,\n         7.4709e-05, -9.8594e-06,  2.0972e-05, -3.0577e-07,  3.7600e-06,\n         8.2952e-05,  7.5098e-05, -1.1940e-05], grad_fn=<SumBackward1>)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out = model(edge_index, batch_pos_neg_labels, edge_weight)\n",
    "# out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# size = len(batch)\n",
    "#\n",
    "# bpr_loss = model.recommendation_loss(out[:size], out[size:], 0) * size\n",
    "# reg_loss = regularization_loss(model.embedding.weight, size, batch_usr, batch_pos_items, batch_neg_items)\n",
    "# loss = bpr_loss + reg_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# bpr_loss_batch_list = []\n",
    "# reg_loss_batch_list = []\n",
    "# final_loss_batch_list = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# bpr_loss_batch_list.append(bpr_loss.item())\n",
    "# reg_loss_batch_list.append(reg_loss.item())\n",
    "# final_loss_batch_list.append(loss.item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# bpr_loss = round(np.mean(bpr_loss_batch_list), 8)\n",
    "# reg_loss = round(np.mean(reg_loss_batch_list), 8)\n",
    "# final_loss = round(np.mean(final_loss_batch_list), 8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpr loss:  tensor(0.6929, grad_fn=<AddBackward0>) reg loss:  2.5e-07 final loss 0.69287777\n"
     ]
    }
   ],
   "source": [
    "# print(\"bpr loss: \", loss, \"reg loss: \", reg_loss, \"final loss\", final_loss)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# bpr_loss_epoch_list = []\n",
    "# reg_loss_epoch_list = []\n",
    "# final_loss_epoch_list = []\n",
    "# recall_epoch_list = []\n",
    "# precision_epoch_list = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     embeds = model.get_embedding(edge_index, edge_weight)   # ?? ???\n",
    "#     final_usr_embed, final_item_embed = torch.split(embeds, (n_users, n_items))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "matrix = interact_matrix(train_df, n_users, n_items)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "test_topK_recall, test_topK_precision = get_metrics(final_usr_embed, final_item_embed, matrix, val_df, 20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  2.7449903925336262e-05 recall:  0.0002744990392533626\n"
     ]
    }
   ],
   "source": [
    "print('precision: ', test_topK_precision, 'recall: ', test_topK_recall)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 6.5503e-05, -1.2144e-05, -3.5105e-05,  ..., -2.7406e-05,\n          4.9693e-06, -6.8124e-05],\n        [-7.2272e-05, -2.6420e-05,  1.3902e-05,  ..., -2.7292e-05,\n         -3.2123e-05, -4.6970e-05],\n        [-6.1275e-06,  5.6032e-05, -2.4367e-05,  ..., -1.6769e-04,\n         -1.6696e-05, -4.8051e-05],\n        ...,\n        [-1.9772e-05,  8.6049e-05, -1.0757e-04,  ..., -2.3527e-05,\n         -1.4579e-05, -2.4870e-05],\n        [ 3.7011e-05, -8.9452e-06,  1.0440e-06,  ...,  2.9516e-05,\n         -4.1773e-05,  2.5515e-05],\n        [-1.4688e-04, -1.2512e-05, -8.6683e-05,  ...,  5.1958e-06,\n          3.2031e-05, -1.0007e-05]])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance_score = final_usr_embed @ final_item_embed.t()\n",
    "relevance_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([55837, 21848])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance_score = matrix = torch.mul(relevance_score, (1 - matrix))\n",
    "relevance_score.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[68953, 61906, 57160, 65925, 72183, 66884, 75556, 64867, 58660, 68567,\n         76008, 55916, 68004, 72730, 57959, 58041, 73858, 67402, 69536, 71235],\n        [60379, 62224, 56314, 74592, 63314, 57673, 67046, 62044, 59997, 75624,\n         61462, 63471, 76928, 69757, 70303, 57168, 75129, 59868, 61044, 67499],\n        [74922, 73959, 65184, 58568, 71186, 71598, 61827, 69022, 68489, 72623,\n         69591, 59018, 74509, 75462, 68181, 59361, 60893, 63412, 70471, 76413],\n        [67858, 58989, 76093, 72266, 75732, 67497, 65922, 69232, 64275, 73523,\n         66349, 57818, 65273, 66434, 69224, 57474, 69060, 74521, 58485, 60997],\n        [68902, 60080, 74127, 74931, 65532, 66609, 61802, 68125, 63193, 77664,\n         59371, 73148, 61979, 60451, 56652, 64926, 58533, 61027, 65662, 73434],\n        [62182, 64137, 76442, 69006, 56525, 63828, 65370, 57310, 74259, 56245,\n         58883, 58902, 60310, 70391, 64302, 59167, 62294, 62193, 62089, 65281]])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_relevance_indices = torch.topk(relevance_score, 20).indices + n_users\n",
    "topk_relevance_indices[0:6]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2565, 3615, 4526, 1155, 2243, 2282, 3804,  437,  775, 1583, 2662, 4791,\n         1505, 3363,  326,  850, 4986, 3243,  152, 2113],\n        [1221, 1365, 3813, 3627, 3836, 3190, 3722,  198, 3091, 1454, 4221,  229,\n          906, 4833, 3938, 2276, 3373, 3600, 4000,  714],\n        [3991, 3492,   88, 1285,  376, 1062, 2144, 1893, 1070, 4829, 3643, 2802,\n          968,  398, 1635, 1026,  135, 3445, 1207, 1627],\n        [2881, 4725, 4520,  333, 2503, 1540,  915,  445, 2594, 4724, 3747,  135,\n          627, 3414, 4910, 3812, 3903,  563, 1867, 3467],\n        [ 488, 4794,  302, 4236, 3975, 3400,  454,   90,  664, 2241, 3914, 2190,\n          924, 3250, 4042, 1715, 2239, 2732, 3422, 3256],\n        [4432, 4330, 2292, 1054, 4223, 2485, 3655, 4589, 2029,   13, 4574, 1789,\n         3842, 3473, 3344, 1615, 3489,  341, 1594, 3313]])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_relevance_indices = torch.topk(relevance_score, 20).indices\n",
    "topk_relevance_indices[0:6]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "       user_ID  \\\n0            0   \n1            1   \n2            2   \n3            3   \n4            4   \n...        ...   \n55832    55832   \n55833    55833   \n55834    55834   \n55835    55835   \n55836    55836   \n\n                                                                                                                                      top_rlvnt_itm  \n0      [68953, 61906, 57160, 65925, 72183, 66884, 75556, 64867, 58660, 68567, 76008, 55916, 68004, 72730, 57959, 58041, 73858, 67402, 69536, 71235]  \n1      [60379, 62224, 56314, 74592, 63314, 57673, 67046, 62044, 59997, 75624, 61462, 63471, 76928, 69757, 70303, 57168, 75129, 59868, 61044, 67499]  \n2      [74922, 73959, 65184, 58568, 71186, 71598, 61827, 69022, 68489, 72623, 69591, 59018, 74509, 75462, 68181, 59361, 60893, 63412, 70471, 76413]  \n3      [67858, 58989, 76093, 72266, 75732, 67497, 65922, 69232, 64275, 73523, 66349, 57818, 65273, 66434, 69224, 57474, 69060, 74521, 58485, 60997]  \n4      [68902, 60080, 74127, 74931, 65532, 66609, 61802, 68125, 63193, 77664, 59371, 73148, 61979, 60451, 56652, 64926, 58533, 61027, 65662, 73434]  \n...                                                                                                                                             ...  \n55832  [64299, 76591, 57933, 72247, 69309, 57926, 59647, 76905, 64896, 56331, 59176, 57818, 65543, 57722, 61798, 58568, 62853, 66775, 57259, 71862]  \n55833  [56101, 66487, 66415, 74465, 60585, 59253, 72778, 64483, 59029, 64827, 69660, 64413, 70982, 59708, 72951, 59596, 66116, 63067, 62456, 58020]  \n55834  [67003, 70988, 70444, 70479, 64497, 75580, 59297, 63397, 65770, 60378, 60057, 61511, 75250, 70652, 72099, 74239, 65402, 66967, 74698, 63418]  \n55835  [68662, 65931, 60242, 69695, 58560, 59252, 73044, 75178, 69302, 69778, 60741, 71776, 71649, 69069, 68339, 63173, 65107, 75160, 65591, 56379]  \n55836  [74643, 70561, 75456, 56441, 63789, 77139, 61957, 73948, 65093, 66724, 75318, 72651, 69612, 70464, 70266, 70576, 57741, 77185, 67854, 71544]  \n\n[55837 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_ID</th>\n      <th>top_rlvnt_itm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>[68953, 61906, 57160, 65925, 72183, 66884, 75556, 64867, 58660, 68567, 76008, 55916, 68004, 72730, 57959, 58041, 73858, 67402, 69536, 71235]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>[60379, 62224, 56314, 74592, 63314, 57673, 67046, 62044, 59997, 75624, 61462, 63471, 76928, 69757, 70303, 57168, 75129, 59868, 61044, 67499]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>[74922, 73959, 65184, 58568, 71186, 71598, 61827, 69022, 68489, 72623, 69591, 59018, 74509, 75462, 68181, 59361, 60893, 63412, 70471, 76413]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>[67858, 58989, 76093, 72266, 75732, 67497, 65922, 69232, 64275, 73523, 66349, 57818, 65273, 66434, 69224, 57474, 69060, 74521, 58485, 60997]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>[68902, 60080, 74127, 74931, 65532, 66609, 61802, 68125, 63193, 77664, 59371, 73148, 61979, 60451, 56652, 64926, 58533, 61027, 65662, 73434]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>55832</th>\n      <td>55832</td>\n      <td>[64299, 76591, 57933, 72247, 69309, 57926, 59647, 76905, 64896, 56331, 59176, 57818, 65543, 57722, 61798, 58568, 62853, 66775, 57259, 71862]</td>\n    </tr>\n    <tr>\n      <th>55833</th>\n      <td>55833</td>\n      <td>[56101, 66487, 66415, 74465, 60585, 59253, 72778, 64483, 59029, 64827, 69660, 64413, 70982, 59708, 72951, 59596, 66116, 63067, 62456, 58020]</td>\n    </tr>\n    <tr>\n      <th>55834</th>\n      <td>55834</td>\n      <td>[67003, 70988, 70444, 70479, 64497, 75580, 59297, 63397, 65770, 60378, 60057, 61511, 75250, 70652, 72099, 74239, 65402, 66967, 74698, 63418]</td>\n    </tr>\n    <tr>\n      <th>55835</th>\n      <td>55835</td>\n      <td>[68662, 65931, 60242, 69695, 58560, 59252, 73044, 75178, 69302, 69778, 60741, 71776, 71649, 69069, 68339, 63173, 65107, 75160, 65591, 56379]</td>\n    </tr>\n    <tr>\n      <th>55836</th>\n      <td>55836</td>\n      <td>[74643, 70561, 75456, 56441, 63789, 77139, 61957, 73948, 65093, 66724, 75318, 72651, 69612, 70464, 70266, 70576, 57741, 77185, 67854, 71544]</td>\n    </tr>\n  </tbody>\n</table>\n<p>55837 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_relevance_indices_df = pd.DataFrame(topk_relevance_indices.cpu().numpy())\n",
    "topk_relevance_indices_df['top_rlvnt_itm'] = topk_relevance_indices_df.values.tolist()\n",
    "topk_relevance_indices_df['user_ID'] = topk_relevance_indices_df.index\n",
    "topk_relevance_indices_df = topk_relevance_indices_df[['user_ID', 'top_rlvnt_itm']]\n",
    "topk_relevance_indices_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "      user_id_idx    item_id_idx\n0               9  [12828, 2301]\n1              16        [12633]\n2              19        [12936]\n3              34        [21064]\n4              47  [17121, 9641]\n...           ...            ...\n3638        55601         [1110]\n3639        55607         [5488]\n3640        55747         [4594]\n3641        55780         [2251]\n3642        55799        [14002]\n\n[3643 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id_idx</th>\n      <th>item_id_idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9</td>\n      <td>[12828, 2301]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16</td>\n      <td>[12633]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19</td>\n      <td>[12936]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34</td>\n      <td>[21064]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>47</td>\n      <td>[17121, 9641]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3638</th>\n      <td>55601</td>\n      <td>[1110]</td>\n    </tr>\n    <tr>\n      <th>3639</th>\n      <td>55607</td>\n      <td>[5488]</td>\n    </tr>\n    <tr>\n      <th>3640</th>\n      <td>55747</td>\n      <td>[4594]</td>\n    </tr>\n    <tr>\n      <th>3641</th>\n      <td>55780</td>\n      <td>[2251]</td>\n    </tr>\n    <tr>\n      <th>3642</th>\n      <td>55799</td>\n      <td>[14002]</td>\n    </tr>\n  </tbody>\n</table>\n<p>3643 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_interacted_items = val_df.groupby('user_id_idx')['item_id_idx'].apply(list).reset_index()\n",
    "test_interacted_items"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "      user_id_idx    item_id_idx  user_ID  \\\n0               9  [12828, 2301]        9   \n1              16        [12633]       16   \n2              19        [12936]       19   \n3              34        [21064]       34   \n4              47  [17121, 9641]       47   \n...           ...            ...      ...   \n3638        55601         [1110]    55601   \n3639        55607         [5488]    55607   \n3640        55747         [4594]    55747   \n3641        55780         [2251]    55780   \n3642        55799        [14002]    55799   \n\n                                                                                                                                     top_rlvnt_itm  \n0     [68780, 58231, 68539, 71708, 65792, 65621, 76969, 63235, 65050, 59871, 76228, 68064, 74592, 60264, 73602, 74730, 71644, 66758, 74514, 67201]  \n1     [72451, 65526, 66905, 70322, 62534, 77137, 59169, 66668, 60812, 61102, 75475, 75044, 74279, 69698, 77154, 59350, 72246, 62717, 76225, 70751]  \n2     [75287, 75767, 60299, 61737, 76128, 72479, 67589, 75825, 62614, 73229, 58816, 76207, 59518, 75276, 65993, 77139, 60387, 63435, 67354, 67914]  \n3     [62304, 70380, 71033, 60507, 66624, 58211, 71919, 71519, 66847, 62329, 55877, 66358, 65670, 75128, 57702, 63089, 59707, 75093, 64499, 66225]  \n4     [59131, 73765, 76128, 67606, 69739, 71819, 71666, 77270, 60841, 76009, 76602, 75770, 64656, 57772, 57256, 62086, 58717, 70292, 65649, 73905]  \n...                                                                                                                                            ...  \n3638  [63308, 65107, 64265, 62099, 70077, 63206, 57981, 63194, 58675, 59667, 58462, 68910, 65612, 76601, 70542, 61576, 74811, 71583, 62569, 74936]  \n3639  [67431, 73624, 71891, 65735, 72983, 61669, 73151, 75909, 59448, 66304, 68771, 71172, 70725, 57288, 77522, 66595, 57802, 74719, 69220, 65932]  \n3640  [70393, 62620, 72378, 73172, 68485, 59062, 62885, 69143, 72402, 73470, 77483, 58416, 74249, 63960, 57507, 76064, 59646, 68004, 72520, 61950]  \n3641  [57929, 64702, 65787, 67361, 63609, 71610, 67988, 73280, 59296, 70380, 69591, 62481, 60418, 60214, 62391, 59538, 68638, 55842, 64421, 57221]  \n3642  [74186, 56964, 74393, 71720, 71203, 56807, 57019, 65463, 56470, 70943, 62960, 74513, 72446, 59477, 62691, 72033, 65060, 59518, 76287, 65295]  \n\n[3643 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id_idx</th>\n      <th>item_id_idx</th>\n      <th>user_ID</th>\n      <th>top_rlvnt_itm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9</td>\n      <td>[12828, 2301]</td>\n      <td>9</td>\n      <td>[68780, 58231, 68539, 71708, 65792, 65621, 76969, 63235, 65050, 59871, 76228, 68064, 74592, 60264, 73602, 74730, 71644, 66758, 74514, 67201]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16</td>\n      <td>[12633]</td>\n      <td>16</td>\n      <td>[72451, 65526, 66905, 70322, 62534, 77137, 59169, 66668, 60812, 61102, 75475, 75044, 74279, 69698, 77154, 59350, 72246, 62717, 76225, 70751]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19</td>\n      <td>[12936]</td>\n      <td>19</td>\n      <td>[75287, 75767, 60299, 61737, 76128, 72479, 67589, 75825, 62614, 73229, 58816, 76207, 59518, 75276, 65993, 77139, 60387, 63435, 67354, 67914]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34</td>\n      <td>[21064]</td>\n      <td>34</td>\n      <td>[62304, 70380, 71033, 60507, 66624, 58211, 71919, 71519, 66847, 62329, 55877, 66358, 65670, 75128, 57702, 63089, 59707, 75093, 64499, 66225]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>47</td>\n      <td>[17121, 9641]</td>\n      <td>47</td>\n      <td>[59131, 73765, 76128, 67606, 69739, 71819, 71666, 77270, 60841, 76009, 76602, 75770, 64656, 57772, 57256, 62086, 58717, 70292, 65649, 73905]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3638</th>\n      <td>55601</td>\n      <td>[1110]</td>\n      <td>55601</td>\n      <td>[63308, 65107, 64265, 62099, 70077, 63206, 57981, 63194, 58675, 59667, 58462, 68910, 65612, 76601, 70542, 61576, 74811, 71583, 62569, 74936]</td>\n    </tr>\n    <tr>\n      <th>3639</th>\n      <td>55607</td>\n      <td>[5488]</td>\n      <td>55607</td>\n      <td>[67431, 73624, 71891, 65735, 72983, 61669, 73151, 75909, 59448, 66304, 68771, 71172, 70725, 57288, 77522, 66595, 57802, 74719, 69220, 65932]</td>\n    </tr>\n    <tr>\n      <th>3640</th>\n      <td>55747</td>\n      <td>[4594]</td>\n      <td>55747</td>\n      <td>[70393, 62620, 72378, 73172, 68485, 59062, 62885, 69143, 72402, 73470, 77483, 58416, 74249, 63960, 57507, 76064, 59646, 68004, 72520, 61950]</td>\n    </tr>\n    <tr>\n      <th>3641</th>\n      <td>55780</td>\n      <td>[2251]</td>\n      <td>55780</td>\n      <td>[57929, 64702, 65787, 67361, 63609, 71610, 67988, 73280, 59296, 70380, 69591, 62481, 60418, 60214, 62391, 59538, 68638, 55842, 64421, 57221]</td>\n    </tr>\n    <tr>\n      <th>3642</th>\n      <td>55799</td>\n      <td>[14002]</td>\n      <td>55799</td>\n      <td>[74186, 56964, 74393, 71720, 71203, 56807, 57019, 65463, 56470, 70943, 62960, 74513, 72446, 59477, 62691, 72033, 65060, 59518, 76287, 65295]</td>\n    </tr>\n  </tbody>\n</table>\n<p>3643 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.merge(test_interacted_items, topk_relevance_indices_df, how='left', left_on='user_id_idx', right_on=['user_ID'])\n",
    "metrics_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "      user_id_idx    item_id_idx  user_ID  \\\n0               9  [12828, 2301]        9   \n1              16        [12633]       16   \n2              19        [12936]       19   \n3              34        [21064]       34   \n4              47  [17121, 9641]       47   \n...           ...            ...      ...   \n3638        55601         [1110]    55601   \n3639        55607         [5488]    55607   \n3640        55747         [4594]    55747   \n3641        55780         [2251]    55780   \n3642        55799        [14002]    55799   \n\n                                                                                                                                     top_rlvnt_itm  \\\n0     [68780, 58231, 68539, 71708, 65792, 65621, 76969, 63235, 65050, 59871, 76228, 68064, 74592, 60264, 73602, 74730, 71644, 66758, 74514, 67201]   \n1     [72451, 65526, 66905, 70322, 62534, 77137, 59169, 66668, 60812, 61102, 75475, 75044, 74279, 69698, 77154, 59350, 72246, 62717, 76225, 70751]   \n2     [75287, 75767, 60299, 61737, 76128, 72479, 67589, 75825, 62614, 73229, 58816, 76207, 59518, 75276, 65993, 77139, 60387, 63435, 67354, 67914]   \n3     [62304, 70380, 71033, 60507, 66624, 58211, 71919, 71519, 66847, 62329, 55877, 66358, 65670, 75128, 57702, 63089, 59707, 75093, 64499, 66225]   \n4     [59131, 73765, 76128, 67606, 69739, 71819, 71666, 77270, 60841, 76009, 76602, 75770, 64656, 57772, 57256, 62086, 58717, 70292, 65649, 73905]   \n...                                                                                                                                            ...   \n3638  [63308, 65107, 64265, 62099, 70077, 63206, 57981, 63194, 58675, 59667, 58462, 68910, 65612, 76601, 70542, 61576, 74811, 71583, 62569, 74936]   \n3639  [67431, 73624, 71891, 65735, 72983, 61669, 73151, 75909, 59448, 66304, 68771, 71172, 70725, 57288, 77522, 66595, 57802, 74719, 69220, 65932]   \n3640  [70393, 62620, 72378, 73172, 68485, 59062, 62885, 69143, 72402, 73470, 77483, 58416, 74249, 63960, 57507, 76064, 59646, 68004, 72520, 61950]   \n3641  [57929, 64702, 65787, 67361, 63609, 71610, 67988, 73280, 59296, 70380, 69591, 62481, 60418, 60214, 62391, 59538, 68638, 55842, 64421, 57221]   \n3642  [74186, 56964, 74393, 71720, 71203, 56807, 57019, 65463, 56470, 70943, 62960, 74513, 72446, 59477, 62691, 72033, 65060, 59518, 76287, 65295]   \n\n     intrsctn_itm  \n0              []  \n1              []  \n2              []  \n3              []  \n4              []  \n...           ...  \n3638           []  \n3639           []  \n3640           []  \n3641           []  \n3642           []  \n\n[3643 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id_idx</th>\n      <th>item_id_idx</th>\n      <th>user_ID</th>\n      <th>top_rlvnt_itm</th>\n      <th>intrsctn_itm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9</td>\n      <td>[12828, 2301]</td>\n      <td>9</td>\n      <td>[68780, 58231, 68539, 71708, 65792, 65621, 76969, 63235, 65050, 59871, 76228, 68064, 74592, 60264, 73602, 74730, 71644, 66758, 74514, 67201]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16</td>\n      <td>[12633]</td>\n      <td>16</td>\n      <td>[72451, 65526, 66905, 70322, 62534, 77137, 59169, 66668, 60812, 61102, 75475, 75044, 74279, 69698, 77154, 59350, 72246, 62717, 76225, 70751]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19</td>\n      <td>[12936]</td>\n      <td>19</td>\n      <td>[75287, 75767, 60299, 61737, 76128, 72479, 67589, 75825, 62614, 73229, 58816, 76207, 59518, 75276, 65993, 77139, 60387, 63435, 67354, 67914]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34</td>\n      <td>[21064]</td>\n      <td>34</td>\n      <td>[62304, 70380, 71033, 60507, 66624, 58211, 71919, 71519, 66847, 62329, 55877, 66358, 65670, 75128, 57702, 63089, 59707, 75093, 64499, 66225]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>47</td>\n      <td>[17121, 9641]</td>\n      <td>47</td>\n      <td>[59131, 73765, 76128, 67606, 69739, 71819, 71666, 77270, 60841, 76009, 76602, 75770, 64656, 57772, 57256, 62086, 58717, 70292, 65649, 73905]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3638</th>\n      <td>55601</td>\n      <td>[1110]</td>\n      <td>55601</td>\n      <td>[63308, 65107, 64265, 62099, 70077, 63206, 57981, 63194, 58675, 59667, 58462, 68910, 65612, 76601, 70542, 61576, 74811, 71583, 62569, 74936]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3639</th>\n      <td>55607</td>\n      <td>[5488]</td>\n      <td>55607</td>\n      <td>[67431, 73624, 71891, 65735, 72983, 61669, 73151, 75909, 59448, 66304, 68771, 71172, 70725, 57288, 77522, 66595, 57802, 74719, 69220, 65932]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3640</th>\n      <td>55747</td>\n      <td>[4594]</td>\n      <td>55747</td>\n      <td>[70393, 62620, 72378, 73172, 68485, 59062, 62885, 69143, 72402, 73470, 77483, 58416, 74249, 63960, 57507, 76064, 59646, 68004, 72520, 61950]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3641</th>\n      <td>55780</td>\n      <td>[2251]</td>\n      <td>55780</td>\n      <td>[57929, 64702, 65787, 67361, 63609, 71610, 67988, 73280, 59296, 70380, 69591, 62481, 60418, 60214, 62391, 59538, 68638, 55842, 64421, 57221]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3642</th>\n      <td>55799</td>\n      <td>[14002]</td>\n      <td>55799</td>\n      <td>[74186, 56964, 74393, 71720, 71203, 56807, 57019, 65463, 56470, 70943, 62960, 74513, 72446, 59477, 62691, 72033, 65060, 59518, 76287, 65295]</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n<p>3643 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df['intrsctn_itm'] = [list(set(a).intersection(b)) for a, b in\n",
    "                                  zip(metrics_df.item_id_idx, metrics_df.top_rlvnt_itm)]\n",
    "metrics_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
