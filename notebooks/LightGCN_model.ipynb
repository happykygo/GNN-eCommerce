{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LightGCN model RecSys"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import networkx as nx\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "import yaml\n",
    "from lightgcn import LightGCN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import *\n",
    "pd.set_option('display.max_colwidth', None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device # = \"cpu\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load Config\n",
    "%cd ..\n",
    "with open(\"params.yaml\") as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Interaction Matrix from csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "interaction_matrix = pd.read_csv(config['data']['preprocessed'] + \"interaction_matrix.csv\")\n",
    "interaction_matrix = interaction_matrix.rename(columns={\"product_id\": \"item_id\"})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "im = interaction_matrix[['user_id', 'item_id', 'weight']].copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Total data size: ', len(im), ', unique user: ', im.user_id.nunique(), ', unique items: ', im.item_id.nunique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ?? Should user never purchase removed at the beginning ??? NO for now!!\n",
    "# mini_im = purchase_users(im)\n",
    "#mini_im = im.sample(200000)  #100000\n",
    "mini_im = im"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Mini dataset size: ', len(mini_im), ', Users at least purchased once: ', len(purchase_users(mini_im)))\n",
    "# print('Valid data percentage: ', f'{len(mini_im)/len(im):.2%}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare Train/ Val/ Test dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(mini_im, test_size=0.1)\n",
    "test_df, val_df = train_test_split(test_df, test_size=0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Mini set unique user: ', mini_im.user_id.nunique(), ', unique items: ', mini_im.item_id.nunique())\n",
    "print(\"Train Size  : \", len(train_df))\n",
    "print(\"Val Size : \", len (val_df))\n",
    "print(\"Test Size : \", len (test_df))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_users, n_items, train_df, train_pos_list_df, val_pos_list_df, test_pos_list_df = prepare_val_test(train_df, val_df, test_df)  # , val_u_i_matrix, test_u_i_matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#users, pos_items, neg_items = pos_neg_edge_index(train_pos_list_df, 1, n_users, n_items)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"After data pipline\")\n",
    "print(\"n_users : \", n_users, \", n_items : \", n_items)\n",
    "print(\"train_df Size  : \", len(train_df))\n",
    "print(\"val_pos_list_df Size : \", len (val_pos_list_df))\n",
    "print(\"test_pos_list_df Size : \", len (test_pos_list_df))\n",
    "#print(\"train set size: \", len(users))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instantiate model and train/val the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "latent_dim = 80     # aim to 128\n",
    "n_layers = 3\n",
    "LR = 0.005\n",
    "K = 20   # Recall@K\n",
    "DECAY = 0.0001   # reg loss\n",
    "BATCH_SIZE = 1024  # train mini batch size\n",
    "n_neg = 3     # number of negative sample edges per each positive edge\n",
    "\n",
    "EPOCHS = 50    # total number of epochs\n",
    "checkpoint_dir = \"model-checkpoints\"\n",
    "\n",
    "model = LightGCN(num_nodes=n_users+n_items, embedding_dim=latent_dim, num_layers=n_layers)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "print(\"Size of Learnable Embedding : \", [x.shape for x in list(model.parameters())])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "edge_index, edge_weight = df_to_graph(train_df, True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bpr_loss, reg_loss, final_loss, recall, precision = \\\n",
    "    train_and_evl(n_users, n_items, n_neg, edge_index, edge_weight, train_pos_list_df, val_pos_list_df, model, optimizer, device=device, EPOCHS=EPOCy default, Tune automatically runs N concurrent trials, where N is the number of CPUs (cores) on your machine.HS, BATCH_SIZE=BATCH_SIZE, K=K, DECAY=DECAY, checkpoint_dir=checkpoint_dir, log_interval=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model = torch.load(checkpoint_dir + \"/LightGCN_best.pt\")\n",
    "best_epoch = best_model['epoch']\n",
    "best_val_precision = best_model['precision']\n",
    "best_val_recall = best_model['recall']\n",
    "\n",
    "test_model = LightGCN(num_nodes=n_users+n_items, embedding_dim=latent_dim, num_layers=n_layers)\n",
    "test_model.load_state_dict(best_model['model_state_dict'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_p, test_recall = evaluation(test_model, n_users, n_items, edge_index, edge_weight, test_pos_list_df, K=20)\n",
    "\n",
    "print(f\"Best epoch {best_epoch}\")\n",
    "print(f\"Test Precision: {test_p:>0.4f}, Recall: {test_recall:>0.4f}\")\n",
    "print(f\"Val Precision: {best_val_precision:>0.4f}, Recall: {best_val_recall:>0.4f}\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
